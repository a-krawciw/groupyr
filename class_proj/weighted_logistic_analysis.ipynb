{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Weighted Group Lasso Experiments\n",
    "CSC 2515 Fall 2022"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install CUDA and cudamat (for python) to enable GPU speedups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from groupyr import LogisticSGL\n",
    "from groupyr.logistic import WeightedLogisticSGL\n",
    "import pandas as pd\n",
    "from pca import (pca, logistic_pca)\n",
    "import linearcorex as lc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def mark_as_categorical(dataframe: pd.DataFrame, category: str):\n",
    "    dataframe[category] = dataframe[category].astype('category')\n",
    "\n",
    "def get_categories(dataframe: pd.DataFrame):\n",
    "    return [col for col in dataframe.select_dtypes(include=\"category\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def create_groups_from_1hot(data_frame: pd.DataFrame):\n",
    "    expanded = pd.get_dummies(data_frame)\n",
    "    groups = {col: [] for col in data_frame}\n",
    "    for idx, col in enumerate(expanded):\n",
    "        category = col.split(\"_\")[0]\n",
    "        groups[category].append(idx)\n",
    "\n",
    "    groups = {k: np.array(v) for k, v in groups.items()}\n",
    "    return expanded, groups"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def expand_data(data):\n",
    "    mark_as_categorical(data, \"MaritalStatus\")\n",
    "    mark_as_categorical(data, \"ApplicationMode\")\n",
    "    mark_as_categorical(data, \"ApplicationOrder\")\n",
    "    mark_as_categorical(data, \"TimeOfDay\")\n",
    "    mark_as_categorical(data, \"PreviousQualification\")\n",
    "    mark_as_categorical(data, \"Nationality\")\n",
    "    mark_as_categorical(data, \"MotherQualification\")\n",
    "    mark_as_categorical(data, \"FatherQualification\")\n",
    "    mark_as_categorical(data, \"MotherOccupation\")\n",
    "    mark_as_categorical(data, \"FatherOccupation\")\n",
    "    mark_as_categorical(data, \"Course\")\n",
    "\n",
    "    target = data.get(\"Target\").replace(['Dropout', 'Graduate', 'Enrolled'], [0, 1, 2]).astype(float)\n",
    "\n",
    "    #Scaling\n",
    "    for col in data.select_dtypes(include=[\"float\",'int'], exclude=\"category\"):\n",
    "        data[col] /= data[col].max()\n",
    "\n",
    "    #Hot 1 and Grouping\n",
    "    expanded_X, group_idxs = create_groups_from_1hot(data.drop(columns=\"Target\"))\n",
    "\n",
    "    return expanded_X, group_idxs, target\n",
    "\n",
    "\n",
    "def stage_data(data, stage):\n",
    "    # staged data feed\n",
    "    if stage == 'sem2':\n",
    "      features = data\n",
    "    elif stage == 'sem1':\n",
    "      features = data.drop(columns = ['Curricular units 2nd sem (credited)',\n",
    "  'Curricular units 2nd sem (enrolled)',\n",
    "  'Curricular units 2nd sem (evaluations)',\n",
    "  'Curricular units 2nd sem (approved)',\n",
    "  'Curricular units 2nd sem (grade)',\n",
    "  'Curricular units 2nd sem (without evaluations)'])\n",
    "    elif stage == 'registration':\n",
    "      features = data.drop(columns = ['Curricular units 1st sem (credited)',\n",
    "  'Curricular units 1st sem (enrolled)',\n",
    "  'Curricular units 1st sem (evaluations)',\n",
    "  'Curricular units 1st sem (approved)',\n",
    "  'Curricular units 1st sem (grade)',\n",
    "  'Curricular units 1st sem (without evaluations)',\n",
    "  'Curricular units 2nd sem (credited)',\n",
    "  'Curricular units 2nd sem (enrolled)',\n",
    "  'Curricular units 2nd sem (evaluations)',\n",
    "  'Curricular units 2nd sem (approved)',\n",
    "  'Curricular units 2nd sem (grade)',\n",
    "  'Curricular units 2nd sem (without evaluations)'])\n",
    "\n",
    "    expanded_X, group_idxs, target = expand_data(features)\n",
    "    X = expanded_X.to_numpy(np.float64)\n",
    "    y = target.to_numpy(np.float64)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=1)\n",
    "\n",
    "    return X_train,X_test,y_train,y_test, group_idxs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def standard_metrics(model, X_train, X_test, y_test, y_train, label=\"\"):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Stats for\", label)\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    print(\"F1 score\", metrics.f1_score(y_test, y_pred, average=None))\n",
    "    print(\"Avg F1 score\", metrics.f1_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Training Score\", model.score(X_train, y_train))\n",
    "    print(\"Testing Score\", model.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "kid_data = pd.read_csv(\"data.csv\", delimiter=\";\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "mark_as_categorical(kid_data, \"MaritalStatus\")\n",
    "mark_as_categorical(kid_data, \"ApplicationMode\")\n",
    "mark_as_categorical(kid_data, \"ApplicationOrder\")\n",
    "mark_as_categorical(kid_data, \"TimeOfDay\")\n",
    "mark_as_categorical(kid_data, \"PreviousQualification\")\n",
    "mark_as_categorical(kid_data, \"Nationality\")\n",
    "mark_as_categorical(kid_data, \"MotherQualification\")\n",
    "mark_as_categorical(kid_data, \"FatherQualification\")\n",
    "mark_as_categorical(kid_data, \"MotherOccupation\")\n",
    "mark_as_categorical(kid_data, \"FatherOccupation\")\n",
    "mark_as_categorical(kid_data, \"Course\")\n",
    "\n",
    "for col in kid_data.select_dtypes(include=[\"float\", \"int\"], exclude=\"category\"):\n",
    "    kid_data[col] /= kid_data[col].max()\n",
    "\n",
    "expanded_X, group_idxs = create_groups_from_1hot(kid_data.drop(columns=\"Target\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Graduate    2209\nDropout     1421\nEnrolled     794\nName: Target, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kid_data.get(\"Target\").value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3539, 255)\n",
      "(3539,)\n"
     ]
    }
   ],
   "source": [
    "from groupyr import LogisticSGLCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_idxs = stage_data(kid_data, \"sem2\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Study of OnevRest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for OneVsRest\n",
      "[[207  48  29]\n",
      " [ 18 405  19]\n",
      " [ 35  73  51]]\n",
      "F1 score [0.76102941 0.83677686 0.39534884]\n",
      "Avg F1 score 0.6643850361593802\n",
      "Training Score 0.8095507205425262\n",
      "Testing Score 0.7491525423728813\n",
      "Stats for Softmax\n",
      "[[205  48  31]\n",
      " [ 20 404  18]\n",
      " [ 34  69  56]]\n",
      "F1 score [0.75506446 0.83904465 0.42424242]\n",
      "Avg F1 score 0.672783844364368\n",
      "Training Score 0.8157671658660639\n",
      "Testing Score 0.751412429378531\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='none', max_iter=10000)\n",
    "one_v_all_log_r = OneVsRestClassifier(model).fit(X_train, y_train)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "standard_metrics(one_v_all_log_r, X_train, X_test, y_test, y_train, \"OneVsRest\")\n",
    "standard_metrics(model, X_train, X_test, y_test, y_train, \"Softmax\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for GB Softmax\n",
      "[[207  43  34]\n",
      " [ 15 414  13]\n",
      " [ 33  70  56]]\n",
      "F1 score [0.76808905 0.85448916 0.42748092]\n",
      "Avg F1 score 0.683353044640187\n",
      "Training Score 0.842045775642837\n",
      "Testing Score 0.7649717514124293\n",
      "Stats for GB OvR\n",
      "[[211  42  31]\n",
      " [ 18 413  11]\n",
      " [ 41  74  44]]\n",
      "F1 score [0.76173285 0.85066941 0.35918367]\n",
      "Avg F1 score 0.6571953128104202\n",
      "Training Score 0.834416501836677\n",
      "Testing Score 0.7548022598870057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model_gb = GradientBoostingClassifier()\n",
    "ovr_gb = OneVsRestClassifier(model_gb).fit(X_train, y_train)\n",
    "model_gb.fit(X_train, y_train)\n",
    "\n",
    "standard_metrics(model_gb, X_train, X_test, y_test, y_train, \"GB Softmax\")\n",
    "standard_metrics(ovr_gb, X_train, X_test, y_test, y_train, \"GB OvR\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for Unregularized registration\n",
      "[[190  47  47]\n",
      " [ 59 308  75]\n",
      " [ 40  63  56]]\n",
      "F1 score [0.66317627 0.71627907 0.33234421]\n",
      "Avg F1 score 0.5705998495625998\n",
      "Training Score 0.6226435188288603\n",
      "Testing Score 0.5705998495625998\n",
      "Stats for Ridge registration\n",
      "[[173  44  67]\n",
      " [ 51 299  92]\n",
      " [ 30  51  78]]\n",
      "F1 score [0.64312268 0.715311   0.39393939]\n",
      "Avg F1 score 0.5841243584346696\n",
      "Training Score 0.6013581315332565\n",
      "Testing Score 0.5841243584346696\n",
      "Stats for Lasso registration\n",
      "[[173  44  67]\n",
      " [ 51 299  92]\n",
      " [ 30  51  78]]\n",
      "F1 score [0.64312268 0.715311   0.39393939]\n",
      "Avg F1 score 0.5841243584346696\n",
      "Training Score 0.6013581315332565\n",
      "Testing Score 0.5841243584346696\n",
      "Stats for Group registration\n",
      "[[173  44  67]\n",
      " [ 51 299  92]\n",
      " [ 30  51  78]]\n",
      "F1 score [0.64312268 0.715311   0.39393939]\n",
      "Avg F1 score 0.5841243584346696\n",
      "Training Score 0.6013581315332565\n",
      "Testing Score 0.5841243584346696\n",
      "Stats for Unregularized sem1\n",
      "[[210  27  47]\n",
      " [ 30 360  52]\n",
      " [ 42  53  64]]\n",
      "F1 score [0.74204947 0.81632653 0.39751553]\n",
      "Avg F1 score 0.6519638428424065\n",
      "Training Score 0.6981878984077842\n",
      "Testing Score 0.6519638428424065\n",
      "Stats for Ridge sem1\n",
      "[[199  34  51]\n",
      " [ 27 372  43]\n",
      " [ 38  58  63]]\n",
      "F1 score [0.72627737 0.82119205 0.39873418]\n",
      "Avg F1 score 0.6487345341526987\n",
      "Training Score 0.6856263976771925\n",
      "Testing Score 0.6487345341526987\n",
      "Stats for Lasso sem1\n",
      "[[199  34  51]\n",
      " [ 27 372  43]\n",
      " [ 38  58  63]]\n",
      "F1 score [0.72627737 0.82119205 0.39873418]\n",
      "Avg F1 score 0.6487345341526987\n",
      "Training Score 0.6856263976771925\n",
      "Testing Score 0.6487345341526987\n",
      "Stats for Group sem1\n",
      "[[199  34  51]\n",
      " [ 27 372  43]\n",
      " [ 38  58  63]]\n",
      "F1 score [0.72627737 0.82119205 0.39873418]\n",
      "Avg F1 score 0.6487345341526987\n",
      "Training Score 0.6856263976771925\n",
      "Testing Score 0.6487345341526987\n",
      "Stats for Unregularized sem2\n",
      "[[218  30  36]\n",
      " [ 15 388  39]\n",
      " [ 21  46  92]]\n",
      "F1 score [0.81040892 0.85651214 0.56441718]\n",
      "Avg F1 score 0.743779413709183\n",
      "Training Score 0.7312555751515969\n",
      "Testing Score 0.743779413709183\n",
      "Stats for Ridge sem2\n",
      "[[205  28  51]\n",
      " [ 16 366  60]\n",
      " [ 24  37  98]]\n",
      "F1 score [0.77504726 0.83848797 0.5326087 ]\n",
      "Avg F1 score 0.715381309046657\n",
      "Training Score 0.7111484237196853\n",
      "Testing Score 0.715381309046657\n",
      "Stats for Lasso sem2\n",
      "[[205  28  51]\n",
      " [ 16 366  60]\n",
      " [ 24  37  98]]\n",
      "F1 score [0.77504726 0.83848797 0.5326087 ]\n",
      "Avg F1 score 0.715381309046657\n",
      "Training Score 0.7111484237196853\n",
      "Testing Score 0.715381309046657\n",
      "Stats for Group sem2\n",
      "[[205  28  51]\n",
      " [ 16 366  60]\n",
      " [ 24  37  98]]\n",
      "F1 score [0.77504726 0.83848797 0.5326087 ]\n",
      "Avg F1 score 0.715381309046657\n",
      "Training Score 0.7111484237196853\n",
      "Testing Score 0.715381309046657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from groupyr.logistic import WeightedLogisticSGL\n",
    "\n",
    "\n",
    "reg_hyper_params = {\n",
    "'estimator__stretching': np.linspace(1, 2, 5),\n",
    "'estimator__alpha': np.logspace(-3, -1, 15)\n",
    "}\n",
    "\n",
    "unreg_hyper_params = {\n",
    "'estimator__stretching': np.linspace(1, 2, 5),\n",
    "}\n",
    "for stage in ['registration', 'sem1', 'sem2']:\n",
    "    X_train, X_test, y_train, y_test, group_idxs = stage_data(kid_data, stage)\n",
    "\n",
    "    unreg_model = OneVsRestClassifier(WeightedLogisticSGL(alpha=0.0, max_iter=10000))\n",
    "    l2_model = OneVsRestClassifier(WeightedLogisticSGL(groups=None, l1_ratio=0, max_iter=10000))\n",
    "    l1_model = OneVsRestClassifier(WeightedLogisticSGL(groups=None, l1_ratio=1, max_iter=10000))\n",
    "    group_model = OneVsRestClassifier(WeightedLogisticSGL(groups=list(group_idxs.values()), l1_ratio=0, max_iter=10000))\n",
    "\n",
    "    clf_un = GridSearchCV(unreg_model, unreg_hyper_params, n_jobs=-1, cv=5,scoring = 'f1_macro').fit(X_train, y_train)\n",
    "    clf_l2 = GridSearchCV(l2_model, reg_hyper_params, n_jobs=-1, cv=5,scoring = 'f1_macro').fit(X_train, y_train)\n",
    "    clf_l1 = GridSearchCV(l1_model, reg_hyper_params, n_jobs=-1, cv=5,scoring = 'f1_macro').fit(X_train, y_train)\n",
    "    clf_group = GridSearchCV(group_model, reg_hyper_params, n_jobs=-1, cv=5,scoring = 'f1_macro').fit(X_train, y_train)\n",
    "\n",
    "    standard_metrics(clf_un, X_train, X_test, y_test, y_train, label=f\"Unregularized {stage}\")\n",
    "    standard_metrics(clf_l2, X_train, X_test, y_test, y_train, label=f\"Ridge {stage}\")\n",
    "    standard_metrics(clf_l1, X_train, X_test, y_test, y_train, label=f\"Lasso {stage}\")\n",
    "    standard_metrics(clf_group, X_train, X_test, y_test, y_train, label=f\"Group {stage}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from groupyr import sgl_path\n",
    "\n",
    "groups = list(group_idxs.values())\n",
    "alphas = np.logspace(-4, 0, 200)\n",
    "path_coefs, path_alphas, path_iters = sgl_path(\n",
    "    X_train, y_train, l1_ratio=0, groups=groups, alphas=alphas, eps=0.00001, n_alphas=200, max_iter=1000, tol=1e-3\n",
    ")\n",
    "\n",
    "group_means = np.array([np.linalg.norm(path_coefs[grp], axis=0) for grp in groups])\n",
    "\n",
    "zero_idx = np.zeros((len(groups), 1), dtype=int\n",
    "    #[np.max(np.where(group_means[i] == 0)[0]) for i in range(len(groups))]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "\n",
    "cmap = plt.get_cmap(\"tab20\")\n",
    "\n",
    "for grp, color, z_idx in zip(groups, cmap.colors, zero_idx):\n",
    "    _ = ax[0].semilogx(\n",
    "        path_alphas, np.abs(path_coefs[grp][:-1].transpose()), color=color\n",
    "    )\n",
    "\n",
    "    _ = ax[0].axvline(path_alphas[z_idx], ls=\":\", color=color)\n",
    "    _ = ax[1].axvline(path_alphas[z_idx], ls=\":\", color=color)\n",
    "\n",
    "_ = ax[1].semilogx(path_alphas, group_means.transpose())\n",
    "\n",
    "_ = ax[1].set_xlabel(r\"$\\log(\\alpha)$\", fontsize=16)\n",
    "_ = ax[0].set_ylabel(r\"$\\left| \\hat{\\beta} \\right|$\", fontsize=16)\n",
    "_ = ax[1].set_ylabel(\n",
    "    r\"$\\left| \\left| \\hat{\\beta}^{(\\ell)} \\right| \\right|_2$\", fontsize=16\n",
    ")\n",
    "_ = ax[0].set_title(r\"SGL regularization path\", fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
